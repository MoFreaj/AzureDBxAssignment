# Candidate’s Databricks Exercise 

1. Create your own virtual network 
1. Provision an Azure Databricks workspace injected in that virtual network previously created 
1. Create one or more clusters on your workspace that will allow you to complete the next steps 
1. Create an ADLS Gen 2 Storage account in azure portal 
1. Create a container in that storage and upload a random csv file to this container 
1. Access/read the csv file as a dataframe in databricks using spark 
1. Create an external and managed delta table in the Databricks workspace 
1. Create a Databricks Workflow which triggers a notebook with a streaming scenario perhaps… 
1. Trigger the previously created workflow using the Databricks Jobs API 
1. (Possibly Register a serve a model. Get predictions from the served model.) 
